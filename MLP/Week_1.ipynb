{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The objective of this notebook is to demonstrate ``sklearn`` dataset API\n",
    "\n",
    "Recall that it has three APIs\n",
    "1. Loaders (``load_*``) load small standard datasets bundled with ``sklearn``\n",
    "2. Fetchers (``fetch_*``) fetch large datasets from the internet and loads in memory.\n",
    "3. Generators (``generate_``) generate controlled synthetic datasets\n",
    "\n",
    "Loaders and fetchers return a ``bunch`` object and generators return a tuple of feature matrix and label vector(or matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a ``Bunch`` object ``data`` which is a dictionary like object with following attributes\n",
    "- ``data``, which has a feature matrix\n",
    "- ``target``, which is the label vector\n",
    "- ``feature_names`` contain names of the features\n",
    "- ``target_names`` contain the names of the classes\n",
    "- ``DESCR`` has the full description of the dataset\n",
    "- ``filename`` has the path to the location of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access them one by one and examine their contents. For example, we can access ``feature_names`` as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the names of features of this dataset.\n",
    "\n",
    "Let's examine the names of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three classes ``setosa, versicolor, virginica``.\n",
    "\n",
    "The feature matrix can be accessed as follows ``data.data``. Lets take a look at first five examples in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe 4 features per example.\n",
    "\n",
    "Let's examine the shape of the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 150 examples and each example has 4 features.\n",
    "\n",
    "Finally we will examine the label vector and its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 50 examples each from three classes : 0,1,2\n",
    "\n",
    "We can read additional documentation about ``load_iris`` in the following manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_X_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Load and return the iris dataset (classification).\n",
      "\n",
      "The iris dataset is a classic and very easy multi-class classification\n",
      "dataset.\n",
      "\n",
      "=================   ==============\n",
      "Classes                          3\n",
      "Samples per class               50\n",
      "Samples total                  150\n",
      "Dimensionality                   4\n",
      "Features            real, positive\n",
      "=================   ==============\n",
      "\n",
      "Read more in the :ref:`User Guide <iris_dataset>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "return_X_y : bool, default=False\n",
      "    If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "    below for more information about the `data` and `target` object.\n",
      "\n",
      "    .. versionadded:: 0.18\n",
      "\n",
      "as_frame : bool, default=False\n",
      "    If True, the data is a pandas DataFrame including columns with\n",
      "    appropriate dtypes (numeric). The target is\n",
      "    a pandas DataFrame or Series depending on the number of target columns.\n",
      "    If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "    DataFrames or Series as described below.\n",
      "\n",
      "    .. versionadded:: 0.23\n",
      "\n",
      "Returns\n",
      "-------\n",
      "data : :class:`~sklearn.utils.Bunch`\n",
      "    Dictionary-like object, with the following attributes.\n",
      "\n",
      "    data : {ndarray, dataframe} of shape (150, 4)\n",
      "        The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "        DataFrame.\n",
      "    target: {ndarray, Series} of shape (150,)\n",
      "        The classification target. If `as_frame=True`, `target` will be\n",
      "        a pandas Series.\n",
      "    feature_names: list\n",
      "        The names of the dataset columns.\n",
      "    target_names: list\n",
      "        The names of target classes.\n",
      "    frame: DataFrame of shape (150, 5)\n",
      "        Only present when `as_frame=True`. DataFrame with `data` and\n",
      "        `target`.\n",
      "\n",
      "        .. versionadded:: 0.23\n",
      "    DESCR: str\n",
      "        The full description of the dataset.\n",
      "    filename: str\n",
      "        The path to the location of the data.\n",
      "\n",
      "        .. versionadded:: 0.20\n",
      "\n",
      "(data, target) : tuple if ``return_X_y`` is True\n",
      "\n",
      "    .. versionadded:: 0.18\n",
      "\n",
      "Notes\n",
      "-----\n",
      "    .. versionchanged:: 0.20\n",
      "        Fixed two wrong data points according to Fisher's paper.\n",
      "        The new version is the same as in R, but not as in the UCI\n",
      "        Machine Learning Repository.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Let's say you are interested in the samples 10, 25, and 50, and want to\n",
      "know their class name.\n",
      "\n",
      ">>> from sklearn.datasets import load_iris\n",
      ">>> data = load_iris()\n",
      ">>> data.target[[10, 25, 50]]\n",
      "array([0, 0, 1])\n",
      ">>> list(data.target_names)\n",
      "['setosa', 'versicolor', 'virginica']\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_base.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "?load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, we can load and examine different datasets.\n",
    "\n",
    "We can obtain feature matrix and label or target from ``load_iris`` and other loaders in general by setting ``return_X_y`` argument to ``True``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature matrix: (150, 4)\n",
      "Shape of label vector: (150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix, label_vector = load_iris(return_X_y=True)\n",
    "print('Shape of feature matrix:', feature_matrix.shape)\n",
    "print('Shape of label vector:', label_vector.shape)\n",
    "'''\n",
    "We can also view the full details of the dataset with data.DESCR\n",
    "'''\n",
    "data.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional details about this loader can accessed from the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mload_diabetes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_X_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Load and return the diabetes dataset (regression).\n",
      "\n",
      "==============   ==================\n",
      "Samples total    442\n",
      "Dimensionality   10\n",
      "Features         real, -.2 < x < .2\n",
      "Targets          integer 25 - 346\n",
      "==============   ==================\n",
      "\n",
      ".. note::\n",
      "   The meaning of each feature (i.e. `feature_names`) might be unclear\n",
      "   (especially for `ltg`) as the documentation of the original dataset is\n",
      "   not explicit. We provide information that seems correct in regard with\n",
      "   the scientific literature in this field of research.\n",
      "\n",
      "Read more in the :ref:`User Guide <diabetes_dataset>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "return_X_y : bool, default=False.\n",
      "    If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "    See below for more information about the `data` and `target` object.\n",
      "\n",
      "    .. versionadded:: 0.18\n",
      "\n",
      "as_frame : bool, default=False\n",
      "    If True, the data is a pandas DataFrame including columns with\n",
      "    appropriate dtypes (numeric). The target is\n",
      "    a pandas DataFrame or Series depending on the number of target columns.\n",
      "    If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "    DataFrames or Series as described below.\n",
      "\n",
      "    .. versionadded:: 0.23\n",
      "\n",
      "Returns\n",
      "-------\n",
      "data : :class:`~sklearn.utils.Bunch`\n",
      "    Dictionary-like object, with the following attributes.\n",
      "\n",
      "    data : {ndarray, dataframe} of shape (442, 10)\n",
      "        The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "        DataFrame.\n",
      "    target: {ndarray, Series} of shape (442,)\n",
      "        The regression target. If `as_frame=True`, `target` will be\n",
      "        a pandas Series.\n",
      "    feature_names: list\n",
      "        The names of the dataset columns.\n",
      "    frame: DataFrame of shape (442, 11)\n",
      "        Only present when `as_frame=True`. DataFrame with `data` and\n",
      "        `target`.\n",
      "\n",
      "        .. versionadded:: 0.23\n",
      "    DESCR: str\n",
      "        The full description of the dataset.\n",
      "    data_filename: str\n",
      "        The path to the location of the data.\n",
      "    target_filename: str\n",
      "        The path to the location of the target.\n",
      "\n",
      "(data, target) : tuple if ``return_X_y`` is True\n",
      "\n",
      "    .. versionadded:: 0.18\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_base.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "?load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
      "         0.01990842, -0.01764613],\n",
      "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
      "        -0.06832974, -0.09220405],\n",
      "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
      "         0.00286377, -0.02593034],\n",
      "       ...,\n",
      "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
      "        -0.04687948,  0.01549073],\n",
      "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
      "         0.04452837, -0.02593034],\n",
      "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
      "        -0.00421986,  0.00306441]]), 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
      "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
      "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
      "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
      "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
      "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
      "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
      "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
      "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
      "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
      "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
      "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
      "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
      "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
      "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
      "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
      "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
      "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
      "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
      "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
      "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
      "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
      "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
      "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
      "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
      "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
      "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
      "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
      "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
      "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
      "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
      "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
      "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
      "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
      "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
      "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
      "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
      "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
      "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
      "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
      "       220.,  57.]), 'frame': None, 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)', 'feature_names': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'data_filename': '/home/mourya/anaconda3/lib/python3.9/site-packages/sklearn/datasets/data/diabetes_data.csv.gz', 'target_filename': '/home/mourya/anaconda3/lib/python3.9/site-packages/sklearn/datasets/data/diabetes_target.csv.gz'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calling the loader and obtaining the Bunch Object\n",
    "'''\n",
    "data = load_diabetes()\n",
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "X,y = load_diabetes(as_frame=True,return_X_y=True)\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Description of the Bunch object\n",
    "'''\n",
    "data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Shape of the feature matrix\n",
    "'''\n",
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Shape of target vector\n",
    "'''\n",
    "data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621,  0.02187235, -0.0442235 ,\n",
       "        -0.03482076, -0.04340085, -0.00259226,  0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, -0.02632783, -0.00844872,\n",
       "        -0.01916334,  0.07441156, -0.03949338, -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, -0.00567061, -0.04559945,\n",
       "        -0.03419447, -0.03235593, -0.00259226,  0.00286377, -0.02593034],\n",
       "       [-0.08906294, -0.04464164, -0.01159501, -0.03665645,  0.01219057,\n",
       "         0.02499059, -0.03603757,  0.03430886,  0.02269202, -0.00936191],\n",
       "       [ 0.00538306, -0.04464164, -0.03638469,  0.02187235,  0.00393485,\n",
       "         0.01559614,  0.00814208, -0.00259226, -0.03199144, -0.04664087]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "First five examples of feature matrix\n",
    "'''\n",
    "data.data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "First five examples of labels\n",
    "'''\n",
    "data.target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Names of features\n",
    "'''\n",
    "data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetchers\n",
    "\n",
    "### fetch_openml\n",
    "[openml.org](https://openml.org) is a public repository for machine learning data and experiments, that allows everybody to upload open datasets\n",
    "\n",
    "Import the library and access the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mfetch_openml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mversion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'active'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdata_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdata_home\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtarget_column\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'default-target'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreturn_X_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mas_frame\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Fetch dataset from openml by name or dataset id.\n",
      "\n",
      "Datasets are uniquely identified by either an integer ID or by a\n",
      "combination of name and version (i.e. there might be multiple\n",
      "versions of the 'iris' dataset). Please give either name or data_id\n",
      "(not both). In case a name is given, a version can also be\n",
      "provided.\n",
      "\n",
      "Read more in the :ref:`User Guide <openml>`.\n",
      "\n",
      ".. versionadded:: 0.20\n",
      "\n",
      ".. note:: EXPERIMENTAL\n",
      "\n",
      "    The API is experimental (particularly the return value structure),\n",
      "    and might have small backward-incompatible changes without notice\n",
      "    or warning in future releases.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "name : str, default=None\n",
      "    String identifier of the dataset. Note that OpenML can have multiple\n",
      "    datasets with the same name.\n",
      "\n",
      "version : int or 'active', default='active'\n",
      "    Version of the dataset. Can only be provided if also ``name`` is given.\n",
      "    If 'active' the oldest version that's still active is used. Since\n",
      "    there may be more than one active version of a dataset, and those\n",
      "    versions may fundamentally be different from one another, setting an\n",
      "    exact version is highly recommended.\n",
      "\n",
      "data_id : int, default=None\n",
      "    OpenML ID of the dataset. The most specific way of retrieving a\n",
      "    dataset. If data_id is not given, name (and potential version) are\n",
      "    used to obtain a dataset.\n",
      "\n",
      "data_home : str, default=None\n",
      "    Specify another download and cache folder for the data sets. By default\n",
      "    all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "\n",
      "target_column : str, list or None, default='default-target'\n",
      "    Specify the column name in the data to use as target. If\n",
      "    'default-target', the standard target column a stored on the server\n",
      "    is used. If ``None``, all columns are returned as data and the\n",
      "    target is ``None``. If list (of strings), all columns with these names\n",
      "    are returned as multi-target (Note: not all scikit-learn classifiers\n",
      "    can handle all types of multi-output combinations)\n",
      "\n",
      "cache : bool, default=True\n",
      "    Whether to cache downloaded datasets using joblib.\n",
      "\n",
      "return_X_y : bool, default=False\n",
      "    If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "    below for more information about the `data` and `target` objects.\n",
      "\n",
      "as_frame : bool or 'auto', default='auto'\n",
      "    If True, the data is a pandas DataFrame including columns with\n",
      "    appropriate dtypes (numeric, string or categorical). The target is\n",
      "    a pandas DataFrame or Series depending on the number of target_columns.\n",
      "    The Bunch will contain a ``frame`` attribute with the target and the\n",
      "    data. If ``return_X_y`` is True, then ``(data, target)`` will be pandas\n",
      "    DataFrames or Series as describe above.\n",
      "\n",
      "    If as_frame is 'auto', the data and target will be converted to\n",
      "    DataFrame or Series as if as_frame is set to True, unless the dataset\n",
      "    is stored in sparse format.\n",
      "\n",
      "    .. versionchanged:: 0.24\n",
      "       The default value of `as_frame` changed from `False` to `'auto'`\n",
      "       in 0.24.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "\n",
      "data : :class:`~sklearn.utils.Bunch`\n",
      "    Dictionary-like object, with the following attributes.\n",
      "\n",
      "    data : np.array, scipy.sparse.csr_matrix of floats, or pandas DataFrame\n",
      "        The feature matrix. Categorical features are encoded as ordinals.\n",
      "    target : np.array, pandas Series or DataFrame\n",
      "        The regression target or classification labels, if applicable.\n",
      "        Dtype is float if numeric, and object if categorical. If\n",
      "        ``as_frame`` is True, ``target`` is a pandas object.\n",
      "    DESCR : str\n",
      "        The full description of the dataset\n",
      "    feature_names : list\n",
      "        The names of the dataset columns\n",
      "    target_names: list\n",
      "        The names of the target columns\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "    categories : dict or None\n",
      "        Maps each categorical feature name to a list of values, such\n",
      "        that the value encoded as i is ith in the list. If ``as_frame``\n",
      "        is True, this is None.\n",
      "    details : dict\n",
      "        More metadata from OpenML\n",
      "    frame : pandas DataFrame\n",
      "        Only present when `as_frame=True`. DataFrame with ``data`` and\n",
      "        ``target``.\n",
      "\n",
      "(data, target) : tuple if ``return_X_y`` is True\n",
      "\n",
      "    .. note:: EXPERIMENTAL\n",
      "\n",
      "        This interface is **experimental** and subsequent releases may\n",
      "        change attributes without notice (although there should only be\n",
      "        minor changes to ``data`` and ``target``).\n",
      "\n",
      "    Missing values in the 'data' are represented as NaN's. Missing values\n",
      "    in 'target' are represented as NaN's (numerical target) or None\n",
      "    (categorical target)\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "?fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this is an experimental API and will likely change in the future releases.\n",
    "> We use this API for loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28789/2946015983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_784'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_X_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature matrix shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mfetch_openml\u001b[0;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;31m# obtain the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_DATA_FILE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_description\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m     bunch = _download_data_to_bunch(url, return_sparse, data_home,\n\u001b[0m\u001b[1;32m    916\u001b[0m                                     \u001b[0mas_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                                     \u001b[0mfeatures_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_download_data_to_bunch\u001b[0;34m(url, sparse, data_home, as_frame, features_list, data_columns, target_columns, shape, md5_checksum)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnominal_attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     out = _retry_with_clean_cache(url, data_home)(\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0m_load_arff_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                              \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_load_arff_response\u001b[0;34m(url, data_home, return_type, encode_nominal, parse_arff, md5_checksum)\u001b[0m\n\u001b[1;32m    516\u001b[0m                           encode_nominal=encode_nominal)\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mparsed_arff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_arff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# consume remaining stream, if early exited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_convert_arff_data_dataframe\u001b[0;34m(arff, columns, features_dict)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns_to_keep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_chunk_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marff_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns_to_keep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_chunk_generator\u001b[0;34m(gen, chunksize)\u001b[0m\n\u001b[1;32m    666\u001b[0m     chunk may have a length less than ``chunksize``.\"\"\"\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/externals/_arff.py\u001b[0m in \u001b[0;36mdecode_rows\u001b[0;34m(self, stream, conversors)\u001b[0m\n\u001b[1;32m    473\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mBadDataFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/externals/_arff.py\u001b[0m in \u001b[0;36m_decode_values\u001b[0;34m(values, conversors)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decode_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             values = [None if value is None else conversor(value)\n\u001b[0m\u001b[1;32m    481\u001b[0m                       \u001b[0;32mfor\u001b[0m \u001b[0mconversor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                       in zip(conversors, values)]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/externals/_arff.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decode_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             values = [None if value is None else conversor(value)\n\u001b[0m\u001b[1;32m    481\u001b[0m                       \u001b[0;32mfor\u001b[0m \u001b[0mconversor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                       in zip(conversors, values)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, y = fetch_openml('mnist_784',version=1,return_X_y=True)\n",
    "print('Feature matrix shape:', X.shape)\n",
    "print('Label shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators\n",
    "### ``make_regression``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmake_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_informative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_targets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0meffective_rank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtail_strength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcoef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Generate a random regression problem.\n",
      "\n",
      "The input set can either be well conditioned (by default) or have a low\n",
      "rank-fat tail singular profile. See :func:`make_low_rank_matrix` for\n",
      "more details.\n",
      "\n",
      "The output is generated by applying a (potentially biased) random linear\n",
      "regression model with `n_informative` nonzero regressors to the previously\n",
      "generated input and some gaussian centered noise with some adjustable\n",
      "scale.\n",
      "\n",
      "Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_samples : int, default=100\n",
      "    The number of samples.\n",
      "\n",
      "n_features : int, default=100\n",
      "    The number of features.\n",
      "\n",
      "n_informative : int, default=10\n",
      "    The number of informative features, i.e., the number of features used\n",
      "    to build the linear model used to generate the output.\n",
      "\n",
      "n_targets : int, default=1\n",
      "    The number of regression targets, i.e., the dimension of the y output\n",
      "    vector associated with a sample. By default, the output is a scalar.\n",
      "\n",
      "bias : float, default=0.0\n",
      "    The bias term in the underlying linear model.\n",
      "\n",
      "effective_rank : int, default=None\n",
      "    if not None:\n",
      "        The approximate number of singular vectors required to explain most\n",
      "        of the input data by linear combinations. Using this kind of\n",
      "        singular spectrum in the input allows the generator to reproduce\n",
      "        the correlations often observed in practice.\n",
      "    if None:\n",
      "        The input set is well conditioned, centered and gaussian with\n",
      "        unit variance.\n",
      "\n",
      "tail_strength : float, default=0.5\n",
      "    The relative importance of the fat noisy tail of the singular values\n",
      "    profile if `effective_rank` is not None. When a float, it should be\n",
      "    between 0 and 1.\n",
      "\n",
      "noise : float, default=0.0\n",
      "    The standard deviation of the gaussian noise applied to the output.\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Shuffle the samples and the features.\n",
      "\n",
      "coef : bool, default=False\n",
      "    If True, the coefficients of the underlying linear model are returned.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Determines random number generation for dataset creation. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "X : ndarray of shape (n_samples, n_features)\n",
      "    The input samples.\n",
      "\n",
      "y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      "    The output values.\n",
      "\n",
      "coef : ndarray of shape (n_features,) or (n_features, n_targets)\n",
      "    The coefficient of the underlying linear model. It is returned only if\n",
      "    coef is True.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_samples_generator.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "?make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1\n",
    "\n",
    "Let's generate 100 samples with 5 features for a single label regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=5, n_targets=1, shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to set seed so that we get to see repeatability in the experimentation\n",
    "\n",
    "Let's look at the shapes of the feature matrix and label vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2\n",
    "\n",
    "Lets generate 100 samples with 5 features for a multi output regression problem with 5 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=5, n_targets=5, shuffle=True,random_state=42)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``make_classification``\n",
    "\n",
    "Generate a random n-class classification problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmake_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_informative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_redundant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_repeated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_clusters_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mflip_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclass_sep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhypercube\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Generate a random n-class classification problem.\n",
      "\n",
      "This initially creates clusters of points normally distributed (std=1)\n",
      "about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
      "length ``2*class_sep`` and assigns an equal number of clusters to each\n",
      "class. It introduces interdependence between these features and adds\n",
      "various types of further noise to the data.\n",
      "\n",
      "Without shuffling, ``X`` horizontally stacks features in the following\n",
      "order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
      "linear combinations of the informative features, followed by ``n_repeated``\n",
      "duplicates, drawn randomly with replacement from the informative and\n",
      "redundant features. The remaining features are filled with random noise.\n",
      "Thus, without shuffling, all useful features are contained in the columns\n",
      "``X[:, :n_informative + n_redundant + n_repeated]``.\n",
      "\n",
      "Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_samples : int, default=100\n",
      "    The number of samples.\n",
      "\n",
      "n_features : int, default=20\n",
      "    The total number of features. These comprise ``n_informative``\n",
      "    informative features, ``n_redundant`` redundant features,\n",
      "    ``n_repeated`` duplicated features and\n",
      "    ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
      "    drawn at random.\n",
      "\n",
      "n_informative : int, default=2\n",
      "    The number of informative features. Each class is composed of a number\n",
      "    of gaussian clusters each located around the vertices of a hypercube\n",
      "    in a subspace of dimension ``n_informative``. For each cluster,\n",
      "    informative features are drawn independently from  N(0, 1) and then\n",
      "    randomly linearly combined within each cluster in order to add\n",
      "    covariance. The clusters are then placed on the vertices of the\n",
      "    hypercube.\n",
      "\n",
      "n_redundant : int, default=2\n",
      "    The number of redundant features. These features are generated as\n",
      "    random linear combinations of the informative features.\n",
      "\n",
      "n_repeated : int, default=0\n",
      "    The number of duplicated features, drawn randomly from the informative\n",
      "    and the redundant features.\n",
      "\n",
      "n_classes : int, default=2\n",
      "    The number of classes (or labels) of the classification problem.\n",
      "\n",
      "n_clusters_per_class : int, default=2\n",
      "    The number of clusters per class.\n",
      "\n",
      "weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
      "    The proportions of samples assigned to each class. If None, then\n",
      "    classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
      "    then the last class weight is automatically inferred.\n",
      "    More than ``n_samples`` samples may be returned if the sum of\n",
      "    ``weights`` exceeds 1. Note that the actual class proportions will\n",
      "    not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
      "\n",
      "flip_y : float, default=0.01\n",
      "    The fraction of samples whose class is assigned randomly. Larger\n",
      "    values introduce noise in the labels and make the classification\n",
      "    task harder. Note that the default setting flip_y > 0 might lead\n",
      "    to less than ``n_classes`` in y in some cases.\n",
      "\n",
      "class_sep : float, default=1.0\n",
      "    The factor multiplying the hypercube size.  Larger values spread\n",
      "    out the clusters/classes and make the classification task easier.\n",
      "\n",
      "hypercube : bool, default=True\n",
      "    If True, the clusters are put on the vertices of a hypercube. If\n",
      "    False, the clusters are put on the vertices of a random polytope.\n",
      "\n",
      "shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
      "    Shift features by the specified value. If None, then features\n",
      "    are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "\n",
      "scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
      "    Multiply features by the specified value. If None, then features\n",
      "    are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "    happens after shifting.\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Shuffle the samples and the features.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Determines random number generation for dataset creation. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "X : ndarray of shape (n_samples, n_features)\n",
      "    The generated samples.\n",
      "\n",
      "y : ndarray of shape (n_samples,)\n",
      "    The integer labels for class membership of each sample.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "the \"Madelon\" dataset.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "       selection benchmark\", 2003.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "make_blobs : Simplified variant.\n",
      "make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_samples_generator.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "?make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets generate a binary classification problem with 10 features and 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=100, n_features=10, n_classes=2, n_clusters_per_class=1,random_state=42)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11422765, -1.71016839, -0.06822216, -0.14928517,  0.30780177,\n",
       "         0.15030176, -0.05694562, -0.22595246, -0.36361221, -0.13818757],\n",
       "       [ 0.70775194, -1.57022472, -0.23503183, -0.63604713,  0.62180996,\n",
       "        -0.56246678,  0.97255445, -0.77719676,  0.63240774, -0.47809669],\n",
       "       [ 0.63859246,  0.04739867,  0.33273433,  1.1046981 , -0.65183611,\n",
       "        -1.66152006, -1.2110162 ,  1.09821151, -0.0660798 ,  0.68024225],\n",
       "       [-0.23894805, -0.97755524,  0.0379061 ,  0.19896733,  0.50091719,\n",
       "        -0.90756366,  0.75539123,  0.12437227, -0.57677133,  0.07871283],\n",
       "       [-0.59239392, -0.05023811,  0.17573204, -1.43949185,  0.27045683,\n",
       "        -0.86399077, -0.83095012,  0.60046915,  0.04852163,  0.32557953]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets generate a 3-class classification problem with 10 features and 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=100, n_features=10, n_classes=3, n_clusters_per_class=1,random_state=42)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.58351628 -1.73833907 -1.37298251 -1.77311485  0.45918008  0.83392215\n",
      "  -1.66096093  0.20768769 -0.07016571  0.42961822]\n",
      " [-1.0044394  -1.43862044  0.47335819 -0.21188291  0.0125924   0.22409248\n",
      "  -0.77300978  0.49799829  0.0976761   0.02451017]\n",
      " [ 0.07740833  0.19896733  0.12437227  0.17738132 -0.97755524  0.50091719\n",
      "   0.75138712  0.54336019  0.09933231 -1.66940528]\n",
      " [-0.91759569 -0.9609536   1.07746664  0.4522739  -0.32138584 -0.8254972\n",
      "  -0.56372455  0.24368721  0.41293145 -0.8222204 ]\n",
      " [-0.96222828 -0.96090774  1.21530116  0.55980482 -1.24778318 -0.25256815\n",
      "  -1.43014138  0.13074058  1.6324113  -0.44004449]]\n",
      "y : [2 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])\n",
    "print(\"y :\",y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``make_multilabel_classification``\n",
    "\n",
    "This function helps us generate a random multi-label classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmake_multilabel_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mallow_unlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreturn_indicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dense'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreturn_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Generate a random multilabel classification problem.\n",
      "\n",
      "For each sample, the generative process is:\n",
      "    - pick the number of labels: n ~ Poisson(n_labels)\n",
      "    - n times, choose a class c: c ~ Multinomial(theta)\n",
      "    - pick the document length: k ~ Poisson(length)\n",
      "    - k times, choose a word: w ~ Multinomial(theta_c)\n",
      "\n",
      "In the above process, rejection sampling is used to make sure that\n",
      "n is never zero or more than `n_classes`, and that the document length\n",
      "is never zero. Likewise, we reject classes which have already been chosen.\n",
      "\n",
      "Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_samples : int, default=100\n",
      "    The number of samples.\n",
      "\n",
      "n_features : int, default=20\n",
      "    The total number of features.\n",
      "\n",
      "n_classes : int, default=5\n",
      "    The number of classes of the classification problem.\n",
      "\n",
      "n_labels : int, default=2\n",
      "    The average number of labels per instance. More precisely, the number\n",
      "    of labels per sample is drawn from a Poisson distribution with\n",
      "    ``n_labels`` as its expected value, but samples are bounded (using\n",
      "    rejection sampling) by ``n_classes``, and must be nonzero if\n",
      "    ``allow_unlabeled`` is False.\n",
      "\n",
      "length : int, default=50\n",
      "    The sum of the features (number of words if documents) is drawn from\n",
      "    a Poisson distribution with this expected value.\n",
      "\n",
      "allow_unlabeled : bool, default=True\n",
      "    If ``True``, some instances might not belong to any class.\n",
      "\n",
      "sparse : bool, default=False\n",
      "    If ``True``, return a sparse feature matrix\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       parameter to allow *sparse* output.\n",
      "\n",
      "return_indicator : {'dense', 'sparse'} or False, default='dense'\n",
      "    If ``'dense'`` return ``Y`` in the dense binary indicator format. If\n",
      "    ``'sparse'`` return ``Y`` in the sparse binary indicator format.\n",
      "    ``False`` returns a list of lists of labels.\n",
      "\n",
      "return_distributions : bool, default=False\n",
      "    If ``True``, return the prior class probability and conditional\n",
      "    probabilities of features given classes, from which the data was\n",
      "    drawn.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Determines random number generation for dataset creation. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "X : ndarray of shape (n_samples, n_features)\n",
      "    The generated samples.\n",
      "\n",
      "Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n",
      "    The label sets. Sparse matrix should be of CSR format.\n",
      "\n",
      "p_c : ndarray of shape (n_classes,)\n",
      "    The probability of each class being drawn. Only returned if\n",
      "    ``return_distributions=True``.\n",
      "\n",
      "p_w_c : ndarray of shape (n_features, n_classes)\n",
      "    The probability of each feature being drawn given each class.\n",
      "    Only returned if ``return_distributions=True``.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_samples_generator.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "?make_multilabel_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets generate 100 samples with 10 features, 5 labels and on average 2 labels per example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_multilabel_classification(n_samples=100,n_features=10,n_classes=5,n_labels=2)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``make_blobs``\n",
    "\n",
    "``make_blobs`` enables us to generate random data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmake_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcenters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcluster_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcenter_box\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreturn_centers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Generate isotropic Gaussian blobs for clustering.\n",
      "\n",
      "Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_samples : int or array-like, default=100\n",
      "    If int, it is the total number of points equally divided among\n",
      "    clusters.\n",
      "    If array-like, each element of the sequence indicates\n",
      "    the number of samples per cluster.\n",
      "\n",
      "    .. versionchanged:: v0.20\n",
      "        one can now pass an array-like to the ``n_samples`` parameter\n",
      "\n",
      "n_features : int, default=2\n",
      "    The number of features for each sample.\n",
      "\n",
      "centers : int or ndarray of shape (n_centers, n_features), default=None\n",
      "    The number of centers to generate, or the fixed center locations.\n",
      "    If n_samples is an int and centers is None, 3 centers are generated.\n",
      "    If n_samples is array-like, centers must be\n",
      "    either None or an array of length equal to the length of n_samples.\n",
      "\n",
      "cluster_std : float or array-like of float, default=1.0\n",
      "    The standard deviation of the clusters.\n",
      "\n",
      "center_box : tuple of float (min, max), default=(-10.0, 10.0)\n",
      "    The bounding box for each cluster center when centers are\n",
      "    generated at random.\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Shuffle the samples.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Determines random number generation for dataset creation. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "return_centers : bool, default=False\n",
      "    If True, then return the centers of each cluster\n",
      "\n",
      "    .. versionadded:: 0.23\n",
      "\n",
      "Returns\n",
      "-------\n",
      "X : ndarray of shape (n_samples, n_features)\n",
      "    The generated samples.\n",
      "\n",
      "y : ndarray of shape (n_samples,)\n",
      "    The integer labels for cluster membership of each sample.\n",
      "\n",
      "centers : ndarray of shape (n_centers, n_features)\n",
      "    The centers of each cluster. Only returned if\n",
      "    ``return_centers=True``.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import make_blobs\n",
      ">>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,\n",
      "...                   random_state=0)\n",
      ">>> print(X.shape)\n",
      "(10, 2)\n",
      ">>> y\n",
      "array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])\n",
      ">>> X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,\n",
      "...                   random_state=0)\n",
      ">>> print(X.shape)\n",
      "(10, 2)\n",
      ">>> y\n",
      "array([0, 1, 2, 0, 2, 2, 2, 1, 1, 0])\n",
      "\n",
      "See Also\n",
      "--------\n",
      "make_classification : A more intricate variant.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_samples_generator.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "?make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets generate a random dataset of 10 samples with 2 features each for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "X,y = make_blobs(n_samples=10,centers=3,n_features=2,random_state=42)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the cluster membership of each point in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9244b6adea22edad6e19cdea93c196ea7ddff3c1d91dfb077ea542e13d85dd05"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
